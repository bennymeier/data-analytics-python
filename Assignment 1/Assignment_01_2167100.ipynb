{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Variables\n",
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning values to variables\n",
    "price = 20\n",
    "currency = \"euro\"\n",
    "product = \"teapot\"\n",
    "\n",
    "# Printing the sentence\n",
    "print(f\"Today I bought a {product} for {price} {currency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking user for first and last name\n",
    "first_name = input(\"Please enter your first name: \")\n",
    "last_name = input(\"Please enter your last name: \")\n",
    "\n",
    "# Displaying the full name\n",
    "print(f\"Your full name is {first_name} {last_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Strings\n",
    "### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given string\n",
    "text = \"the weather is really great today\"\n",
    "\n",
    "# a) Adding an exclamation mark\n",
    "text_with_exclamation = text + \"!\"\n",
    "print(text_with_exclamation)\n",
    "\n",
    "# b) Capitalizing each word\n",
    "capitalized_text = text.title()\n",
    "print(capitalized_text)\n",
    "\n",
    "# Using slicing to return the word \"Weather\"\n",
    "sliced_word = capitalized_text[4:11]\n",
    "print(sliced_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given string\n",
    "sentence = \"The University of Bamberg offers a wide range of study programs\"\n",
    "\n",
    "# Counting occurrences of 'a'\n",
    "count_a = sentence.count('a')\n",
    "print(f\"The letter 'a' appears {count_a} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python Lists, Sets, Tuples, Dictionaries\n",
    "### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial list\n",
    "stationery = [\"planer\", \"pen\", \"notebook\", \"eraser\"]\n",
    "print(f\"Initial list: {stationery}\")\n",
    "\n",
    "# a) Adding \"marker\" before \"pen\"\n",
    "stationery.insert(1, \"marker\")\n",
    "print(f\"Add 'marker' before 'pen': {stationery}\")\n",
    "\n",
    "# b) Sorting in alphabetical descending order\n",
    "stationery.sort(reverse=True)\n",
    "print(f\"Sort alphabetical in descending order: {stationery}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define both sets\n",
    "IceCreamShop1 = {\"chocolate\", \"wild berry\", \"vanilla\", \"tiramisu\"}\n",
    "IceCreamShop2 = {\"walnut\", \"vanilla\", \"hazelnut\", \"chocolate\"}\n",
    "\n",
    "# Find common elements\n",
    "common_flavors = IceCreamShop1.intersection(IceCreamShop2)\n",
    "print(\"Common flavors:\", common_flavors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given tuple\n",
    "menu_items = (\"spaghetti\", \"cola\", \"beer\", \"water\", \"cake\", \"pie\")\n",
    "\n",
    "# a) Access using negative indexing\n",
    "print(\"Third last item:\", menu_items[-3])\n",
    "\n",
    "# b) Unpacking the tuple\n",
    "main_course, beverage1, beverage2, beverage3, dessert1, dessert2 = menu_items\n",
    "print(\"Main course:\", main_course)\n",
    "print(\"Beverage:\", beverage1, beverage2, beverage3)\n",
    "print(\"Desserts:\", dessert1, dessert2)\n",
    "\n",
    "# c) Modify the tuple by changing the tuple to a list and back to a tuple\n",
    "menu_items_list = list(menu_items)\n",
    "menu_items_list[1] = \"juice\"\n",
    "menu_items = tuple(menu_items_list)\n",
    "print(menu_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a nested dictionary\n",
    "top_songs = {\n",
    "    1: {\"title\": \"Blinding Lights\", \"artist\": \"The Weeknd\", \"release_year\": 2019},\n",
    "    2: {\"title\": \"The Twist\", \"artist\": \"Chubby Checker\", \"release_year\": 1960},\n",
    "    3: {\"title\": \"Smooth\", \"artist\": \"Santana featuring Rob Thomas\", \"release_year\": 1999},\n",
    "    4: {\"title\": \"Mack the Knife\", \"artist\": \"Bobby Darin\", \"release_year\": 1959},\n",
    "    5: {\"title\": \"Uptown Funk\", \"artist\": \"Mark Ronson featuring Bruno Mars\", \"release_year\": 2015}\n",
    "}\n",
    "print(top_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding genres\n",
    "genres = {\n",
    "    \"Blinding Lights\": \"pop\",\n",
    "    \"The Twist\": \"rock and roll\",\n",
    "    \"Smooth\": \"latin rock\",\n",
    "    \"Mack the Knife\": \"classic jazz\",\n",
    "    \"Uptown Funk\": \"funk\"\n",
    "}\n",
    "\n",
    "# Update the dictionary\n",
    "for song in top_songs.values():\n",
    "    song.update({\"genre\": genres[song[\"title\"]]})\n",
    "\n",
    "print(top_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Python NumPy\n",
    "### 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Creating a 3D array\n",
    "arr3D = np.array([[[1, 2, 3]], [[1, 2, 3]], [[4, 5, 6]], [[4, 5, 6]]])\n",
    "print(arr3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the third element of the second array in the third array\n",
    "print(\"The third element:\", arr3D[2, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given 1D array\n",
    "arr1D = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12])\n",
    "\n",
    "# Transforming to 3D array -> 11 arrays that contains one array with one element each\n",
    "arr3D_new = arr1D.reshape((11, 1, 1))\n",
    "print(arr3D_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Python Pandas\n",
    "### 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Converting the top_songs dictionary to DataFrame\n",
    "df_songs = pd.DataFrame.from_dict({(i): top_songs[i]\n",
    "                                  for i in top_songs.keys()},\n",
    "                                  orient='index')\n",
    "print(df_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel files\n",
    "df_names = pd.read_excel('names.xlsx')\n",
    "df_ages = pd.read_excel('ages.xlsx')\n",
    "df_cities = pd.read_excel('cities.xlsx')\n",
    "df_occupations = pd.read_excel('occupations.xlsx')\n",
    "\n",
    "# Combining DataFrames\n",
    "combined_df = pd.concat([df_names, df_ages, df_cities, df_occupations], axis=1)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "customer_orders = pd.read_csv('customer_orders.csv', delimiter=';')\n",
    "print(customer_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are wrong formatted and false values in a row that doesn't fit to the rest of the data. The error is `error: Expected 5 fields in line 20, saw 7`. That means that the parser expected 5 fields per line but found 7 fields in line 20. This is because the CSV file is delimited by `;` (semicolons). It only needs 5 delimiters for the column titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and skip bad lines\n",
    "customer_orders = pd.read_csv('customer_orders.csv', delimiter=';', on_bad_lines=\"skip\")\n",
    "print(f\"{customer_orders.head()}\\n\")\n",
    "print(f\"Types: \\n{customer_orders.dtypes}\\n\")\n",
    "\n",
    "# Cast the 'Order Placed' column to datetime\n",
    "customer_orders['Order Placed'] = pd.to_datetime(customer_orders['Order Placed'])\n",
    "\n",
    "# Change 'Yes' to True and 'No' to False in 'First Purchase' column\n",
    "customer_orders['First Purchase'] = customer_orders['First Purchase'].map({'Yes': True, 'No': False})\n",
    "print(f\"{customer_orders['First Purchase'].head()}\\n\")\n",
    "print(f\"New Types: \\n{customer_orders.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One easy approach is to just skip bad lines but first consider whether the skipped data is essential. If those rows are important we have to use another approach to repair the malformed data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
